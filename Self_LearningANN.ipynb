{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, state_size, action_size, learning_rate=0.001, gamma=0.99):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.gamma = gamma\n",
        "        self.q_values = torch.zeros((state_size, action_size), dtype=torch.float32, requires_grad=True)\n",
        "        self.optimizer = optim.Adam([self.q_values], lr=learning_rate)\n",
        "\n",
        "    def select_action(self, state):\n",
        "        with torch.no_grad():\n",
        "            return torch.argmax(self.q_values[state]).unsqueeze(0)\n",
        "\n",
        "    def update_q_values(self, state, action, reward, next_state):\n",
        "        q_value = self.q_values[state, action]\n",
        "        next_max_q_value = torch.max(self.q_values[next_state]).item()\n",
        "        target_q_value = reward + self.gamma * next_max_q_value\n",
        "        loss = nn.MSELoss()(q_value, target_q_value)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "def add_noise(images, mean=0, std=0.1):\n",
        "    noise = torch.randn(images.size()) * std + mean\n",
        "    return images + noise\n",
        "\n",
        "def train_cnn(cnn, train_loader, criterion, optimizer, epoch, print_freq=100):\n",
        "    cnn.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = cnn(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "        if i % print_freq == 0:\n",
        "            print(f\"Epoch {epoch}, Example {i}, Loss: {running_loss / print_freq:.4f}, Acc: {100 * correct / total:.2f}%\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "def evaluate_cnn(cnn, dataloader):\n",
        "    cnn.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            outputs = cnn(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Accuracy : {accuracy:.2f}%\")\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "cifar_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_size = int(0.8 * len(cifar_dataset))\n",
        "train_dataset, val_dataset = random_split(cifar_dataset, [train_size, len(cifar_dataset) - train_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "cnn = CNN()\n",
        "q_agent = QLearningAgent(state_size=10, action_size=10)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "cnn_optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(5):\n",
        "    train_cnn(cnn, train_loader, criterion, cnn_optimizer, epoch)\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "        cnn.eval()\n",
        "        with torch.no_grad():\n",
        "            cnn_predictions = cnn(inputs)\n",
        "        state = torch.argmax(cnn_predictions, dim=1)\n",
        "        action = q_agent.select_action(state)\n",
        "        noisy_inputs = add_noise(inputs)\n",
        "        q_agent_predictions = cnn(noisy_inputs)\n",
        "        reward = torch.eq(torch.tensor(action), torch.argmax(q_agent_predictions, dim=1)).float()\n",
        "        next_state = torch.argmax(q_agent_predictions, dim=1)\n",
        "        q_agent.update_q_values(state, action, reward, next_state)\n",
        "        cnn.train()\n",
        "        cnn_optimizer.zero_grad()\n",
        "        cnn_outputs = cnn(noisy_inputs)\n",
        "        cnn_loss = criterion(cnn_outputs, torch.argmax(q_agent_predictions, dim=1))\n",
        "        cnn_loss.backward()\n",
        "        cnn_optimizer.step()\n",
        "\n",
        "    evaluate_cnn(cnn, val_loader)\n"
      ],
      "metadata": {
        "id": "BurRtFINunic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KSg3g1Z80WE4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}